{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1 ANN  from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbargaje/Deep-Learning/blob/master/ANN_from_scratch_IRIS_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TQWQkn1NK9Jr",
        "colab_type": "code",
        "outputId": "679b6144-b510-47d2-dc17-3491ebe27f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "Y = iris.target\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "UWViJIFXK9Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#spliting of data into training and testing data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
        "#spliting of training data into training and validation data\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id8QYwnsK9K8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def InitializeWeights(nodes):\n",
        "    #Initialize weights with random values in [-1, 1] (including bias)\n",
        "    layers, weights = len(nodes), []\n",
        "    \n",
        "    for i in range(1, layers):\n",
        "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
        "              for j in range(nodes[i])]\n",
        "        weights.append(np.matrix(w))\n",
        "    \n",
        "    return weights\n",
        "def Train(X, Y, lr, weights):\n",
        "    layers = len(weights)\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
        "        \n",
        "        activations = ForwardPropagation(x, weights, layers)\n",
        "        weights = BackPropagation(y, activations, weights, layers)\n",
        "\n",
        "    return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R00j5eV5K9LW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ForwardPropagation(x, weights, layers):\n",
        "    activations, layer_input = [x], x\n",
        "    \n",
        "    for j in range(layers):\n",
        "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
        "        activations.append(activation)\n",
        "        layer_input = np.append(1, activation) # Augment with bias\n",
        "    return activations\n",
        "  \n",
        "def Sigmoid(x):\n",
        "    return (2 / (1 + np.exp(-2*x)))-1\n",
        "  \n",
        "def SigmoidDerivative(x):\n",
        "    return 1-np.multiply(x, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cDOxbUfsK9Ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def BackPropagation(y, activations, weights, layers):\n",
        "    outputFinal = activations[-1]\n",
        "    error = np.matrix(y - outputFinal) # Error at output\n",
        "    \n",
        "    for j in range(layers, 0, -1):\n",
        "        currActivation = activations[j]\n",
        "        \n",
        "        if(j > 1):\n",
        "            # Augment previous activation\n",
        "            prevActivation = np.append(1, activations[j-1])\n",
        "        else:\n",
        "            # First hidden layer, prevActivation is input (without bias)\n",
        "            prevActivation = activations[0]\n",
        "        \n",
        "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
        "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
        "\n",
        "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
        "        error = np.dot(delta, w) # Calculate error for current layer\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35hd1rkbK9MB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
        "    hidden_layers = len(nodes) - 1\n",
        "    weights = InitializeWeights(nodes)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        weights = Train(X_train, Y_train, lr, weights)\n",
        "\n",
        "        if(epoch % 50 == 0):\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "            if X_val.any():\n",
        "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
        "            \n",
        "    return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Re-eL0QpK9MT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Predict(item, weights):\n",
        "    layers = len(weights)\n",
        "    item = np.append(1, item) # Augment feature vector\n",
        "    \n",
        "    ##_Forward Propagation_##\n",
        "    activations = ForwardPropagation(item, weights, layers)\n",
        "    \n",
        "    outputFinal = activations[-1].A1\n",
        "    index = FindMaxActivation(outputFinal)\n",
        "\n",
        "    # Initialize prediction vector to zeros\n",
        "    y = [0 for i in range(len(outputFinal))]\n",
        "    y[index] = 1  # Set guessed class to 1\n",
        "\n",
        "    return y # Return prediction vector\n",
        "\n",
        "\n",
        "def FindMaxActivation(output):\n",
        "    \"\"\"Find max activation in output\"\"\"\n",
        "    m, index = output[0], 0\n",
        "    for i in range(1, len(output)):\n",
        "        if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "    return index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mr9TCWvAK9Md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Accuracy(X, Y, weights):\n",
        "    correct = 0\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], list(Y[i])\n",
        "        guess = Predict(x, weights)\n",
        "\n",
        "        if(y == guess):\n",
        "            # Guessed correctly\n",
        "            correct += 1\n",
        "    return correct / len(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ymCBw-aK9NO",
        "colab_type": "code",
        "outputId": "dcef71c3-cd60-4862-b715-323ce1749b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        }
      },
      "cell_type": "code",
      "source": [
        "#print(len(X[0]))\n",
        "#print(len(Y[0]))\n",
        "layers = [f, 10, 5, o] # Number of nodes in layers\n",
        "lr, epochs = 0.1, 1000\n",
        "\n",
        "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr)\n",
        "\n",
        "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "3\n",
            "Epoch 50\n",
            "Training Accuracy:0.9824561403508771\n",
            "Validation Accuracy:0.9230769230769231\n",
            "Epoch 100\n",
            "Training Accuracy:0.9385964912280702\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 150\n",
            "Training Accuracy:0.9385964912280702\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 200\n",
            "Training Accuracy:0.9385964912280702\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 250\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 300\n",
            "Training Accuracy:0.9122807017543859\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 350\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 400\n",
            "Training Accuracy:0.9385964912280702\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 450\n",
            "Training Accuracy:0.9385964912280702\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 500\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 550\n",
            "Training Accuracy:0.9649122807017544\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 600\n",
            "Training Accuracy:0.9298245614035088\n",
            "Validation Accuracy:0.7692307692307693\n",
            "Epoch 650\n",
            "Training Accuracy:0.9649122807017544\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 700\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 750\n",
            "Training Accuracy:0.9824561403508771\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 800\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 850\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 900\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 950\n",
            "Training Accuracy:0.9649122807017544\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Epoch 1000\n",
            "Training Accuracy:0.9649122807017544\n",
            "Validation Accuracy:0.8461538461538461\n",
            "Testing Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}